{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imsave, imshow, imread_collection, concatenate_images\n",
    "from skimage.color import gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from keras.utils import Progbar\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.core import Dropout, Lambda, Activation\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose,Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, Adamax, Nadam, RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from dataset_stage2 import DSB18Dataset, _DEFAULT_DS_NUCLEI_VAL_TEST_OPTIONS, _DEFAULT_DS_CONTOURS_VAL_TEST_OPTIONS\n",
    "from post_stage2 import Post, _DEFAULT_PROC_OPTIONS\n",
    "from visualize import display_sem_label_gt_vs_pred, display_sem_label_gt_and_pred\n",
    "from visualize import display_image_and_pred_sem_label, display_image_and_pred_masks\n",
    "from submission_stage2 import DSB18Submission\n",
    "\n",
    "# Import cyclic LR\n",
    "from clr_callback import *\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "\n",
    "# Setting seed for reproducability\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "# np.random.seed = seed\n",
    "smooth = 1.\n",
    "#epochs = 48\n",
    "#epochs = 50\n",
    "#epochs = 70\n",
    "#epochs = 150\n",
    "epochs = 300\n",
    "\n",
    "# Number of test samples to display in notebook\n",
    "num_samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: You MUST set dataset_root to the correct path on your machine!\n",
    "if sys.platform.startswith(\"win\"):\n",
    "    dataset_root = \"E:/datasets/dsb18.retrain\"\n",
    "else:\n",
    "    dataset_root = \"/media/EDrive/datasets/dsb18.retrain\"\n",
    "TRAIN_PATH = dataset_root + \"/stage1_train/\"\n",
    "TEST_PATH = dataset_root + \"/stage2_test_final/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "train_folder = TRAIN_PATH\n",
    "samples = glob.glob(train_folder+'/**/')\n",
    "n_samples = len(samples)\n",
    "print ('number of samples:',n_samples)\n",
    "print(samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function read train images and mask return as nump array\n",
    "def read_train_data(IMG_WIDTH=256,IMG_HEIGHT=256,IMG_CHANNELS=3):\n",
    "    X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "    Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    print('Getting and resizing train images and masks ... ')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if os.path.isfile(\"train_img_256x256_retrained.npy\"):\n",
    "        print(\"Train file train_img_256x256_retrained.npy loaded from memory\")\n",
    "        X_train = np.load(\"train_img_256x256_retrained.npy\")\n",
    "    else:\n",
    "        a = Progbar(len(train_ids))\n",
    "        for n, id_ in enumerate(train_ids):\n",
    "            path = TRAIN_PATH + id_\n",
    "            img = imread(path + '/images/' + id_ + '.png')\n",
    "            if len(img.shape) == 2:\n",
    "                img = gray2rgb(img)\n",
    "                if img.dtype == np.uint16:\n",
    "                    img = (img // 255).astype(np.uint8)\n",
    "            else:\n",
    "                img = img[:,:,:IMG_CHANNELS]\n",
    "            img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "            X_train[n] = img\n",
    "            a.update(n)\n",
    "        np.save(\"train_img_256x256_retrained.npy\",X_train)\n",
    "        \n",
    "    if os.path.isfile(\"train_mask_256x256_retrained.npy\"):\n",
    "        print(\"Train file train_mask_256x256_retrained.npy loaded from memory\")\n",
    "        Y_train = np.load(\"train_mask_256x256_retrained.npy\")\n",
    "    else:\n",
    "        a = Progbar(len(train_ids))\n",
    "        for n, id_ in enumerate(train_ids):\n",
    "            path = TRAIN_PATH + id_\n",
    "            mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "            for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "                mask_ = imread(path + '/masks/' + mask_file)\n",
    "                mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                            preserve_range=True), axis=-1)\n",
    "                mask = np.maximum(mask, mask_)\n",
    "            Y_train[n] = mask\n",
    "            a.update(n)\n",
    "        np.save(\"train_mask_256x256_retrained.npy\",Y_train)\n",
    "        \n",
    "    return X_train,Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function read train images and contours return as nump array\n",
    "def read_train_contour_data(IMG_WIDTH=256,IMG_HEIGHT=256,IMG_CHANNELS=3):\n",
    "    X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "    Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    print('Getting and resizing train images and masks ... ')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if os.path.isfile(\"train_img_256x256_retrained.npy\"):\n",
    "        print(\"Train file train_img_256x256_retrained.npy loaded from memory\")\n",
    "        X_train = np.load(\"train_img_256x256_retrained.npy\")\n",
    "    else:\n",
    "        a = Progbar(len(train_ids))\n",
    "        for n, id_ in enumerate(train_ids):\n",
    "            path = TRAIN_PATH + id_\n",
    "            img = imread(path + '/images/' + id_ + '.png')\n",
    "            if len(img.shape) == 2:\n",
    "                img = gray2rgb(img)\n",
    "                if img.dtype == np.uint16:\n",
    "                    img = (img // 255).astype(np.uint8)\n",
    "            else:\n",
    "                img = img[:,:,:IMG_CHANNELS]\n",
    "            img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "            X_train[n] = img\n",
    "            a.update(n)\n",
    "        np.save(\"train_img_256x256_retrained.npy\",X_train)\n",
    "        \n",
    "    if os.path.isfile(\"train_2px_contours_256x256_retrained.npy\"):\n",
    "        print(\"Train file train_2px_contours_256x256_retrained.npy loaded from memory\")\n",
    "        Y_train = np.load(\"train_2px_contours_256x256_retrained.npy\")\n",
    "    else:\n",
    "        a = Progbar(len(train_ids))\n",
    "        for n, id_ in enumerate(train_ids):\n",
    "            path = TRAIN_PATH + id_\n",
    "            mask = imread(path + '/contours_2px/' + id_ + '.png')\n",
    "            mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "            mask = np.expand_dims(mask, axis=-1)\n",
    "            Y_train[n] = mask.astype(np.bool)\n",
    "            a.update(n)\n",
    "        np.save(\"train_2px_contours_256x256_retrained.npy\",Y_train)\n",
    "        \n",
    "    return X_train,Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read test images and return as numpy array\n",
    "def read_test_data(IMG_WIDTH=256,IMG_HEIGHT=256,IMG_CHANNELS=3):\n",
    "    X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "    sizes_test = []\n",
    "    print('\\nGetting and resizing test images ... ')\n",
    "    sys.stdout.flush()\n",
    "    if os.path.isfile(\"test_img_256x256_retrained.npy\") and os.path.isfile(\"test_size_256x256_retrained.npy\"):\n",
    "        print(\"Test file loaded from memory\")\n",
    "        X_test = np.load(\"test_img_256x256_retrained.npy\")\n",
    "        sizes_test = np.load(\"test_size_256x256_retrained.npy\")\n",
    "        return X_test,sizes_test\n",
    "    b = Progbar(len(test_ids))\n",
    "    for n, id_ in enumerate(test_ids):\n",
    "        path = TEST_PATH + id_\n",
    "        img = imread(path + '/images/' + id_ + '.png')\n",
    "        if len(img.shape) == 2:\n",
    "            img = gray2rgb(img)\n",
    "            if img.dtype == np.uint16:\n",
    "                img = (img // 255).astype(np.uint8)\n",
    "        else:\n",
    "            img = img[:,:,:IMG_CHANNELS]\n",
    "        sizes_test.append([img.shape[0], img.shape[1]])\n",
    "        img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "        X_test[n] = img\n",
    "        b.update(n)\n",
    "    np.save(\"test_img_256x256_retrained.npy\",X_test)\n",
    "    np.save(\"test_size_256x256_retrained.npy\",sizes_test)\n",
    "    return X_test,sizes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def prob_to_rles(x, cutoff=0.5):\n",
    "    lab_img = label(x > cutoff)\n",
    "    for i in range(1, lab_img.max() + 1):\n",
    "        yield rle_encoding(lab_img == i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the test IDs and generate run-length encodings for each seperate mask identified by skimage\n",
    "def mask_to_rle(preds_test_upsampled):\n",
    "    new_test_ids = []\n",
    "    rles = []\n",
    "    for n, id_ in enumerate(test_ids):\n",
    "        rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
    "        rles.extend(rle)\n",
    "        new_test_ids.extend([id_] * len(rle))\n",
    "    return new_test_ids,rles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric function\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "# Loss funtion\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of image channels (for example 3 in case of RGB, or 1 for grayscale images)\n",
    "INPUT_CHANNELS = 3\n",
    "# Number of output masks (1 in case you predict only one type of objects)\n",
    "OUTPUT_MASK_CHANNELS = 1\n",
    "\n",
    "def double_conv_layer(x, size, dropout, batch_norm):\n",
    "    axis = 3\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(x)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    if dropout > 0:\n",
    "        conv = Dropout(dropout)(conv)\n",
    "    return conv\n",
    "\n",
    "def get_unet(IMG_WIDTH=256,IMG_HEIGHT=256,IMG_CHANNELS=3, dropout_val=0.0, batch_norm=True):\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "    filters = 32\n",
    "    axis = 3\n",
    "\n",
    "    conv_224 = double_conv_layer(inputs, filters, dropout_val, batch_norm)\n",
    "    pool_112 = MaxPooling2D(pool_size=(2, 2))(conv_224)\n",
    "\n",
    "    conv_112 = double_conv_layer(pool_112, 2*filters, dropout_val, batch_norm)\n",
    "    pool_56 = MaxPooling2D(pool_size=(2, 2))(conv_112)\n",
    "\n",
    "    conv_56 = double_conv_layer(pool_56, 4*filters, dropout_val, batch_norm)\n",
    "    pool_28 = MaxPooling2D(pool_size=(2, 2))(conv_56)\n",
    "\n",
    "    conv_28 = double_conv_layer(pool_28, 8*filters, dropout_val, batch_norm)\n",
    "    pool_14 = MaxPooling2D(pool_size=(2, 2))(conv_28)\n",
    "\n",
    "    conv_14 = double_conv_layer(pool_14, 16*filters, dropout_val, batch_norm)\n",
    "    pool_7 = MaxPooling2D(pool_size=(2, 2))(conv_14)\n",
    "\n",
    "    conv_7 = double_conv_layer(pool_7, 32*filters, dropout_val, batch_norm)\n",
    "\n",
    "    up_14 = concatenate([UpSampling2D(size=(2, 2))(conv_7), conv_14], axis=axis)\n",
    "    up_conv_14 = double_conv_layer(up_14, 16*filters, dropout_val, batch_norm)\n",
    "\n",
    "    up_28 = concatenate([UpSampling2D(size=(2, 2))(up_conv_14), conv_28], axis=axis)\n",
    "    up_conv_28 = double_conv_layer(up_28, 8*filters, dropout_val, batch_norm)\n",
    "\n",
    "    up_56 = concatenate([UpSampling2D(size=(2, 2))(up_conv_28), conv_56], axis=axis)\n",
    "    up_conv_56 = double_conv_layer(up_56, 4*filters, dropout_val, batch_norm)\n",
    "\n",
    "    up_112 = concatenate([UpSampling2D(size=(2, 2))(up_conv_56), conv_112], axis=axis)\n",
    "    up_conv_112 = double_conv_layer(up_112, 2*filters, dropout_val, batch_norm)\n",
    "\n",
    "    up_224 = concatenate([UpSampling2D(size=(2, 2))(up_conv_112), conv_224], axis=axis)\n",
    "    up_conv_224 = double_conv_layer(up_224, filters, 0, batch_norm)\n",
    "\n",
    "    conv_final = Conv2D(OUTPUT_MASK_CHANNELS, (1, 1))(up_conv_224)\n",
    "    conv_final = BatchNormalization(axis=axis)(conv_final)\n",
    "    conv_final = Activation('sigmoid')(conv_final)\n",
    "\n",
    "   # model = Model(inputs, conv_final, name=\"YTS_UNET_224\")\n",
    "\n",
    "   # outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv_final], name=\"YTS_UNET_224\")\n",
    "    #myoptim = Adam(lr=0.0009, decay=0.0)\n",
    "    #myoptim = Adam(lr=0.001, decay=0.0)\n",
    "    #myoptim = Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "    #myoptim = Adamax(lr=0.003, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.001)\n",
    "    #myoptim = Adamax(lr=0.0018, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "    myoptim = Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, clipnorm=5.0)\n",
    "    model.compile(optimizer=myoptim,loss='binary_crossentropy', metrics=[dice_coef])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train nuclei semantic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train_data\n",
    "train_img,train_mask = read_train_data()\n",
    "\n",
    "# get test_data\n",
    "test_img,test_img_sizes = read_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get u_net model\n",
    "u_net = get_unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# fit model on train_data\n",
    "print(\"\\nTraining...\")\n",
    "#u_net.fit(train_img,train_mask,batch_size=16,epochs=epochs)\n",
    "# Fit model\n",
    "clr_triangular = CyclicLR(mode='exp_range', gamma=0.99994) # Add cyclic LR\n",
    "earlystopper = EarlyStopping(patience=20, verbose=1)\n",
    "# Reload for cyclic LR finetuning\n",
    "# u_net.load_weights(\"model_train_unet_512x512_nuclei.h5\")\n",
    "checkpointer = ModelCheckpoint('model_retrained_unet_256x256_nuclei_cyclic_lr.h5', verbose=1, save_best_only=True)\n",
    "# checkpointer = ModelCheckpoint('model_train_unet_256x256_nuclei.h5', verbose=1, save_best_only=True)\n",
    "results = u_net.fit(train_img, train_mask, validation_split=0.1, batch_size=8, epochs=epochs, \n",
    "                    callbacks=[clr_triangular, earlystopper, checkpointer])\n",
    "\n",
    "t1 = time.time()                                                                              \n",
    "total = t1-t0\n",
    "print('Training the model took ', total/60, 'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run nuclei semantic segmentation on test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicting\")\n",
    "# Predict on test data\n",
    "# test_mask = u_net.predict(test_img,verbose=1)\n",
    "model = load_model('model_retrained_unet_256x256_nuclei_cyclic_lr.h5', custom_objects={'dice_coef': dice_coef})\n",
    "# model = load_model('model_train_unet_256x256_nuclei.h5', custom_objects={'dice_coef': dice_coef})\n",
    "test_mask = model.predict(test_img, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of upsampled test masks\n",
    "test_mask_upsampled = []\n",
    "for i in range(len(test_mask)):\n",
    "    test_mask_upsampled.append(resize(np.squeeze(test_mask[i]),\n",
    "                                       (test_img_sizes[i][0],test_img_sizes[i][1]), \n",
    "                                       mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predicted semantic segmentation to disk\n",
    "b = Progbar(len(test_ids))\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    folder = TEST_PATH + id_ + '/pred_sem_label_raw/'\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    output_file = folder + id_ + '.png'\n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "    imsave(output_file, test_mask_upsampled[n])\n",
    "    folder = TEST_PATH + id_ + '/pred_sem_label/'\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    output_file = folder + id_ + '.png'\n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "    test_mask_thresholded = np.where(test_mask_upsampled[n] > 0.5, 255, 0)\n",
    "    imsave(output_file, test_mask_thresholded)\n",
    "    b.update(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train contours semantic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train_data\n",
    "train_img,train_contours = read_train_contour_data()\n",
    "\n",
    "# get test_data\n",
    "test_img,test_img_sizes = read_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get u_net model\n",
    "u_net = get_unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# fit model on train_data\n",
    "print(\"\\nTraining...\")\n",
    "#u_net.fit(train_img,train_mask,batch_size=16,epochs=epochs)\n",
    "# Fit model\n",
    "earlystopper = EarlyStopping(patience=20, verbose=1)\n",
    "# u_net.load_weights(\"model_train_unet_256x256_nuclei.h5\")\n",
    "# Reload for cyclic LR finetuning\n",
    "clr_triangular = CyclicLR(mode='exp_range', gamma=0.99994) # Add cyclic LR\n",
    "# u_net.load_weights(\"model_train_unet_256x256_contours_2px.h5\")\n",
    "checkpointer = ModelCheckpoint('model_retrained_unet_256x256_contours_2px_cyclic_lr.h5', verbose=1, save_best_only=True)\n",
    "# checkpointer = ModelCheckpoint('model_train_unet_256x256_contours.h5', verbose=1, save_best_only=True)\n",
    "results = u_net.fit(train_img, train_contours, validation_split=0.1, batch_size=8, epochs=epochs, \n",
    "                    callbacks=[clr_triangular, earlystopper, checkpointer])\n",
    "\n",
    "t1 = time.time()                                                                              \n",
    "total = t1-t0\n",
    "print('Training the model took ', total/60, 'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run contours semantic segmentation on test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicting\")\n",
    "# Predict on test data\n",
    "#test_mask = u_net.predict(test_img,verbose=1)\n",
    "model = load_model('model_retrained_unet_256x256_contours_2px_cyclic_lr.h5', custom_objects={'dice_coef': dice_coef})\n",
    "test_contours = model.predict(test_img, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of upsampled test contours\n",
    "test_contours_upsampled = []\n",
    "for i in range(len(test_contours)):\n",
    "    test_contours_upsampled.append(resize(np.squeeze(test_contours[i]),\n",
    "                                       (test_img_sizes[i][0],test_img_sizes[i][1]), \n",
    "                                       mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predicted contours to disk\n",
    "b = Progbar(len(test_ids))\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    folder = TEST_PATH + id_ + '/pred_contours_2px_raw/'\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    output_file = folder + id_ + '.png'\n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "    imsave(output_file, test_contours_upsampled[n])\n",
    "    folder = TEST_PATH + id_ + '/pred_contours_2px/'\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    output_file = folder + id_ + '.png'\n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "    test_contour_thresholded = np.where(test_contours_upsampled[n] > 0.5, 255, 0)\n",
    "    imsave(output_file, test_contour_thresholded)\n",
    "    b.update(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-process segmented nuclei and contours to generate instance segmentations\n",
    "> Had to split `test.txt` in two (`test_part1.txt` and `test_part2.txt`) and run post-processing in two steps because of OOM errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 (1510 files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate default post-processor\n",
    "post = Post(ds_root=dataset_root, options=_DEFAULT_PROC_OPTIONS)\n",
    "post.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the post-processor\n",
    "post.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 (1509 files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate default post-processor\n",
    "post = Post(ds_root=dataset_root, options=_DEFAULT_PROC_OPTIONS)\n",
    "post.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the post-processor\n",
    "post.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize final results (first few)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset test\n",
    "options=_DEFAULT_DS_CONTOURS_VAL_TEST_OPTIONS.copy()\n",
    "options['mode'] = 'instance_masks'\n",
    "options['input_channels'] = 3\n",
    "ds = DSB18Dataset(phase='test', ds_root=dataset_root, options=options)\n",
    "ds.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images, pred_inst_masks, _, IDs = ds.get_rand_samples_with_inst_masks(num_samples, 'test_with_preds', return_IDs=True, deterministic=True)\n",
    "for image, pred_mask, ID in zip(images, pred_inst_masks, IDs):\n",
    "    # Display two images: original RGB image and RGB image with predicted instance masks overlayed.\n",
    "    # Each mask is displayed in a unique color.\n",
    "    # This is useful to debug issues with instance separation.\n",
    "    display_image_and_pred_masks(image, pred_mask, ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Submission object\n",
    "submit = DSB18Submission(ds_root=dataset_root)\n",
    "submit.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE encode predicted instance masks\n",
    "submit.encode_predicted_instance_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission DataFrame and generate submission CSV\n",
    "submit.to_csv()\n",
    "print(submit.instance_masks_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
